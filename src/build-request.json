{
  "kind": "build_request",
  "title": "Add SEO-friendly robots.txt allowing Googlebot, Bingbot, and PerplexityBot on all paths",
  "priority": "normal",
  "requirements": [
    {
      "id": "REQ-37",
      "text": "Create a standard SEO-friendly `robots.txt` file at `frontend/public/robots.txt` that explicitly allows Googlebot, Bingbot, and PerplexityBot to crawl all paths on the site (no disallow rules).",
      "target": "frontend",
      "source": {
        "messageIds": [
          "msg-1"
        ],
        "quotes": [
          "add a standard robots.txt file (SEO-friendly) to allow googlebot, bingbot, PerplexityBot please, and show me the content after it was created",
          "1. all paths please"
        ]
      },
      "acceptanceCriteria": [
        "A new file exists at `frontend/public/robots.txt`.",
        "`robots.txt` contains explicit rules for `User-agent: Googlebot`, `User-agent: Bingbot`, and `User-agent: PerplexityBot` that allow crawling of `/` (e.g., `Allow: /`).",
        "There are no `Disallow:` rules that block any paths.",
        "The file is served publicly at `https://<deployed-domain>/robots.txt` in the deployed frontend canister."
      ]
    },
    {
      "id": "REQ-38",
      "text": "Provide the final, exact `robots.txt` content in the completion notes after creating the file.",
      "target": "unknown",
      "source": {
        "messageIds": [
          "msg-1"
        ],
        "quotes": [
          "and show me the content after it was created"
        ]
      },
      "acceptanceCriteria": [
        "Completion notes include the full `robots.txt` contents exactly as committed (verbatim, including line breaks)."
      ]
    }
  ],
  "constraints": [
    "Do not add any crawl restrictions (no blocked directories or files).",
    "Do not modify any files under `frontend/src/components/ui` or the immutable hook entrypoints listed in SYSTEM_CONTEXT."
  ],
  "nonGoals": [
    "Generate or add a `sitemap.xml`.",
    "Add crawler rules for bots other than Googlebot, Bingbot, and PerplexityBot (unless they are implicitly allowed by a general rule; the requirement is to explicitly allow these three)."
  ],
  "imageRequirements": {
    "required": [],
    "edits": []
  }
}